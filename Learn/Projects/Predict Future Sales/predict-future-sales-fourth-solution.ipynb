{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Process Involved\n1. Understand our data better in Exploratory Data Analysis -- do necessary data wrangling\n2. Use sales from Oct 2015 as predictions for Nov 2015 (Previous Value Benchmark)\n3. Quick Baseline. Apply some variant of decision tree (wihtout any feature engineering, compare this with previously value benchmark)\n4. Set up cross validation to try out different feature engineering ideas\n5. Tune decision tree models, try to tune and get several diverse models with similar performance\n6. Use Ensemble methods to boost score\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport xgboost as xgb\nimport time","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from math import sqrt\nfrom numpy import loadtxt\nfrom itertools import product\nfrom tqdm import tqdm\nfrom sklearn import preprocessing\nfrom xgboost import plot_tree\nfrom matplotlib import pyplot","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nkernel_with_output = False","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data lading\nif kernel_with_output:\n    sales_train = pd.read_csv('data/sales_train.csv')\n    items = pd.read_csv('data/items.csv')\n    shops = pd.read_csv('data/shops.csv')\n    item_categories = pd.read_csv('data/item_categories.csv')\n    test = pd.read_csv('data/test.csv')\n    sample_submission = pd.read_csv('data/sample_submission.csv')","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Insert missing rows and aggregations\nif kernel_with_output:\n    # For every month we create a grid from all shops/items combinations from that month\n    grid = []\n    for block_num in sales_train['date_block_num'].unique():\n        cur_shops = sales_train[sales_train['date_block_num']==block_num]['shop_id'].unique()\n        cur_items = sales_train[sales_train['date_block_num']==block_num]['item_id'].unique()\n        grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n    index_cols = ['shop_id', 'item_id', 'date_block_num']\n    grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n\n    # Aggregations\n    sales_train['item_cnt_day'] = sales_train['item_cnt_day'].clip(0,20)\n    groups = sales_train.groupby(['shop_id', 'item_id', 'date_block_num'])\n    trainset = groups.agg({'item_cnt_day':'sum', 'item_price':'mean'}).reset_index()\n    trainset = trainset.rename(columns = {'item_cnt_day' : 'item_cnt_month'})\n    trainset['item_cnt_month'] = trainset['item_cnt_month'].clip(0,20)\n\n    trainset = pd.merge(grid,trainset,how='left',on=index_cols)\n    trainset.item_cnt_month = trainset.item_cnt_month.fillna(0)\n\n    # Get category id\n    trainset = pd.merge(trainset, items[['item_id', 'item_category_id']], on = 'item_id')\n    trainset.to_csv('trainset_with_grid.csv')\n\n    trainset.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}