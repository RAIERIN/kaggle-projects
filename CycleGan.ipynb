{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGan.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZdi6bqvcqybobWMD+YOTX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RAIERIN/kaggle-projects/blob/master/CycleGan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6LaFdJU3pd-"
      },
      "source": [
        "**Cycle GAN**\n",
        "\n",
        "A model that aims to solve the image-to-image translation problem. The goal of the image-to-image translation problem is the mapping between an input image and an output image using a training set of aligned image paires. However obtaining paired examples is not always feasible. CycleGAN tries to learn this mapping wihtout requiring paired input-output images using cycle-consistent adversial networks.\n",
        "\n",
        "Cycle-Consistent Adversial Networks. The concept proposes a method that can capture the characteristics of one image domain and figure out how these characteristics could be translated into another image domain, all in the absence of any paired training examples.\n",
        "\n",
        "CycleGAN uses a cycle consistency loss to enable training without the need for paired data. In other words, it can translate from one domain to another without one-to-one mapping between the source and target domain.\n",
        "This opens up the possibility to do a lot of interesting tasks like photo-enhancement, image colorization, style transfer, etc. All you need is the source and the target dataset (which is simply a directory of images).\n",
        "\n",
        "For more go to: \n",
        "* https://keras.io/examples/generative/cyclegan/\n",
        "* https://www.tensorflow.org/tutorials/generative/cyclegan\n",
        "\n",
        "Papers:\n",
        "* https://arxiv.org/pdf/1703.10593.pdf\n",
        "* https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rrn1Pi133y_8"
      },
      "source": [
        "**Set up the input pipeline**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLq83Vq13q2M",
        "outputId": "2fb5713b-0d4a-478a-e467-39d517da645b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip install git+https://github.com/tensorflow/examples.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/tensorflow/examples.git\n",
            "  Cloning https://github.com/tensorflow/examples.git to /tmp/pip-req-build-orr_yuk4\n",
            "  Running command git clone -q https://github.com/tensorflow/examples.git /tmp/pip-req-build-orr_yuk4\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-examples===fb13f7e76d50b446b4b395abcdf09bd4aeddb29a-) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-examples===fb13f7e76d50b446b4b395abcdf09bd4aeddb29a-) (1.15.0)\n",
            "Building wheels for collected packages: tensorflow-examples\n",
            "  Building wheel for tensorflow-examples (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-examples: filename=tensorflow_examples-fb13f7e76d50b446b4b395abcdf09bd4aeddb29a_-cp36-none-any.whl size=138482 sha256=30d2e13ec36d01c49858c61295b17f802904877480ffc07e3a6aee5b7c4433f1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pty80gwv/wheels/83/64/b3/4cfa02dc6f9d16bf7257892c6a7ec602cd7e0ff6ec4d7d714d\n",
            "Successfully built tensorflow-examples\n",
            "Installing collected packages: tensorflow-examples\n",
            "Successfully installed tensorflow-examples-fb13f7e76d50b446b4b395abcdf09bd4aeddb29a-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrowNbv336-9"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gdGCxll39Nk"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvWVFNni4Rmu"
      },
      "source": [
        "## Input Pipeline\n",
        "\n",
        "The notebook is based on the model to translate from images of horses to images of zebras. As mentioned in the paper, apply random jittering and mirroring to the training dataset. These are some of the image augmentation techniques that avoids overfitting.\n",
        "\n",
        "This is similar to what was done in pix2pix\n",
        "\n",
        "In random jittering, the image is resized to 286 x 286 and then randomly cropped to 256 x 256.\n",
        "In random mirroring, the image is randomly flipped horizontally i.e left to right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYHlD24w4OeU"
      },
      "source": [
        "dataset, metadata = tfds"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}